\documentclass[journal,twoside,web]{ieeecolor}
%DIF LATEXDIFF DIFFERENCE FILE
%DIF DEL /home/hbp/Documents/latexdiff-gui/old.tex   Wed Jul 31 11:46:04 2019
%DIF ADD /home/hbp/Documents/latexdiff-gui/new.tex   Wed Jul 31 11:46:04 2019
\usepackage{generic}
\usepackage{cite}

\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}

\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage[pdftex]{graphicx}
\graphicspath{{./figures/}}
\DeclareGraphicsExtensions{.pdf,.jpeg,.png}

\usepackage{textcomp}

\usepackage{siunitx}
\sisetup{per-mode = symbol}
\sisetup{mode=text,range-phrase = {~--~}}

 \usepackage{booktabs}
 \usepackage{multirow}
% \usepackage{graphicx}
 \usepackage{lscape}

\newtheorem{colloary}{Colloary}
\newtheorem{theorem}{\bf Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{example}{Example}
\newtheorem{notation}{Notation}
\newtheorem{definition}{\bf Definition}
\newtheorem{remark}{Remark}

%\newcommand{et al.}{\textit{et al}.~}
\newcommand{\ie}{\textit{i}.\textit{e}.~}
\newcommand{\eg}{\textit{e}.\textit{g}.~}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\markboth{\journalname, VOL. XX, NO. XX, XXXX 2019}
{Qiao \MakeLowercase{\textit{et al.}}: A Survey for Methods and Strategies for High-precision Robotic Grasping and Assembly Tasks -- Some New Trends}
%DIF PREAMBLE EXTENSION ADDED BY LATEXDIFF
%DIF UNDERLINE PREAMBLE %DIF PREAMBLE
\RequirePackage[normalem]{ulem} %DIF PREAMBLE
\RequirePackage{color}\definecolor{RED}{rgb}{1,0,0}\definecolor{BLUE}{rgb}{0,0,1} %DIF PREAMBLE
\providecommand{\DIFadd}[1]{{\protect\color{blue}\uwave{#1}}} %DIF PREAMBLE
\providecommand{\DIFdel}[1]{{\protect\color{red}\sout{#1}}}                      %DIF PREAMBLE
%DIF SAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddbegin}{} %DIF PREAMBLE
\providecommand{\DIFaddend}{} %DIF PREAMBLE
\providecommand{\DIFdelbegin}{} %DIF PREAMBLE
\providecommand{\DIFdelend}{} %DIF PREAMBLE
\providecommand{\DIFmodbegin}{} %DIF PREAMBLE
\providecommand{\DIFmodend}{} %DIF PREAMBLE
%DIF FLOATSAFE PREAMBLE %DIF PREAMBLE
\providecommand{\DIFaddFL}[1]{\DIFadd{#1}} %DIF PREAMBLE
\providecommand{\DIFdelFL}[1]{\DIFdel{#1}} %DIF PREAMBLE
\providecommand{\DIFaddbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFaddendFL}{} %DIF PREAMBLE
\providecommand{\DIFdelbeginFL}{} %DIF PREAMBLE
\providecommand{\DIFdelendFL}{} %DIF PREAMBLE
\newcommand{\DIFscaledelfig}{0.5}
%DIF HIGHLIGHTGRAPHICS PREAMBLE %DIF PREAMBLE
\RequirePackage{settobox} %DIF PREAMBLE
\RequirePackage{letltxmacro} %DIF PREAMBLE
\newsavebox{\DIFdelgraphicsbox} %DIF PREAMBLE
\newlength{\DIFdelgraphicswidth} %DIF PREAMBLE
\newlength{\DIFdelgraphicsheight} %DIF PREAMBLE
% store original definition of \includegraphics %DIF PREAMBLE
\LetLtxMacro{\DIFOincludegraphics}{\includegraphics} %DIF PREAMBLE
\newcommand{\DIFaddincludegraphics}[2][]{{\color{blue}\fbox{\DIFOincludegraphics[#1]{#2}}}} %DIF PREAMBLE
\newcommand{\DIFdelincludegraphics}[2][]{% %DIF PREAMBLE
\sbox{\DIFdelgraphicsbox}{\DIFOincludegraphics[#1]{#2}}% %DIF PREAMBLE
\settoboxwidth{\DIFdelgraphicswidth}{\DIFdelgraphicsbox} %DIF PREAMBLE
\settoboxtotalheight{\DIFdelgraphicsheight}{\DIFdelgraphicsbox} %DIF PREAMBLE
\scalebox{\DIFscaledelfig}{% %DIF PREAMBLE
\parbox[b]{\DIFdelgraphicswidth}{\usebox{\DIFdelgraphicsbox}\\[-\baselineskip] \rule{\DIFdelgraphicswidth}{0em}}\llap{\resizebox{\DIFdelgraphicswidth}{\DIFdelgraphicsheight}{% %DIF PREAMBLE
\setlength{\unitlength}{\DIFdelgraphicswidth}% %DIF PREAMBLE
\begin{picture}(1,1)% %DIF PREAMBLE
\thicklines\linethickness{2pt} %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,0){\framebox(1,1){}}}% %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,0){\line( 1,1){1}}}% %DIF PREAMBLE
{\color[rgb]{1,0,0}\put(0,1){\line(1,-1){1}}}% %DIF PREAMBLE
\end{picture}% %DIF PREAMBLE
}\hspace*{3pt}}} %DIF PREAMBLE
} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddbegin}{\DIFaddbegin} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddend}{\DIFaddend} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelbegin}{\DIFdelbegin} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelend}{\DIFdelend} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddbegin}{\DIFOaddbegin \let\includegraphics\DIFaddincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddend}{\DIFOaddend \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelbegin}{\DIFOdelbegin \let\includegraphics\DIFdelincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelend}{\DIFOaddend \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddbeginFL}{\DIFaddbeginFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOaddendFL}{\DIFaddendFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelbeginFL}{\DIFdelbeginFL} %DIF PREAMBLE
\LetLtxMacro{\DIFOdelendFL}{\DIFdelendFL} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddbeginFL}{\DIFOaddbeginFL \let\includegraphics\DIFaddincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFaddendFL}{\DIFOaddendFL \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelbeginFL}{\DIFOdelbeginFL \let\includegraphics\DIFdelincludegraphics} %DIF PREAMBLE
\DeclareRobustCommand{\DIFdelendFL}{\DIFOaddendFL \let\includegraphics\DIFOincludegraphics} %DIF PREAMBLE
%DIF END PREAMBLE EXTENSION ADDED BY LATEXDIFF

\begin{document}
\title{A Survey for Methods and Strategies for High-precision Robotic Grasping and Assembly Tasks -- Some New Trends}
\author{Hong Qiao, \IEEEmembership{Fellow, IEEE}, Rui Li
\DIFdelbegin %DIFDELCMD < \thanks{Hong Qiao and Rui Li are with the State Key Lab of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and University of Chinese Academy of Sciences, Beijing, China (e-mail: lirui2013@ia.ac.cn; hong.qiao@ia.ac.cn). Hong Qiao is also with Chinese Academy of Sciences Center for Excellence in Brain Science and Intelligence Technology. Rui Li is also with Beijing Key Laboratory of Research and Application for Robotic Intelligence of “Hand-Eye-Brain” Interaction}
%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \thanks{Hong Qiao is with the State Key Lab of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China, and University of Chinese Academy of Sciences, Beijing, China, and Chinese Academy of Sciences Center for Excellence in Brain Science and Intelligence Technology. Rui Li is with Technical University of Munich, Munich 80333, Germany.}
\DIFaddend \thanks{This work is supported partly by The National Key Research and Development Program of China (2017YFB1300200), and partly by the National Natural Science Foundation (NSFC) of China (under grants 61627808, 91648205, 51705515).}}

\maketitle

\begin{abstract}
    Grasping and assembly are essential tasks in high-precision robotic manipulation for industrial manufacturing as well as for home service applications.     
    %DIF < According to statistics, the assembly procedure makes up nearly \SI{50}{\percent} of the total cost of the manufacturing process, and grasping is a prerequisite step for the assembly procedure.
    Many efforts have been devoted to this area, in an attempt to meet the increasing precision requirement of the task. However, it remains a problematic objective to fulfill high precision, high reliability, high speed, and high flexibility all at once during one robotic manipulation task.    
    \DIFdelbegin %DIFDELCMD < 

%DIFDELCMD <     %%%
\DIFdelend To find answers to the above problem, this paper tries to categorize, review and compare the recent works focusing on robotic grasping and assembly tasks to reveal some potential trends in this research area. The approaches will be divided into five groups based on the difference in the utilization of sensing or constraints.     
    %DIF < : 
    %DIF < \begin{enumerate}
    %DIF <     \item Sensing information based high-precision robotic manipulation;
    %DIF <     \item Compliant mechanism/device based high-precision robotic manipulation;
    %DIF <     \item Environmental constraints based high-precision robotic manipulation;
    %DIF <     \item Sensing-constraint integrated high-precision robotic manipulation;
    %DIF <     \item Human-inspired high-precision robotic manipulation.
    %DIF < \end{enumerate}
    For each part, the robotic grasping and assembly will be treated as practical cases to illustrate the concrete work in that area.    
    \DIFdelbegin %DIFDELCMD < 

%DIFDELCMD <     %%%
\DIFdel{It is hoped that this }\DIFdelend \DIFaddbegin \DIFadd{This }\DIFaddend paper could give the readers some knowledge on the current development of the robotic manipulation, and \DIFdelbegin \DIFdel{could }\DIFdelend provide new thoughts on future direction in this area, inspiring new designs, structures and systems to meet new requirements in applications in industrial manufacturing and home service.

\end{abstract}

\begin{IEEEkeywords}
Robotic manipulation, sensing, environmental constraint, assembly, grasping.
\end{IEEEkeywords}

\section{Introduction}
\label{sec:intro}


\IEEEPARstart{H}{ow} to achieve high precision manipulation has always been a primary challenge in the robotic research area. Since the robots’ extensive application in various fields, people have higher expectations and requirements for their manipulation precision.

For instance, in peg-in-hole assembly task for 
(1) quartz accelerometer (a kind of linear accelerometer unit which is widely used in navigation and guidance system for airplane and ships), the concentricity between the quartz reed and coil should be less than $\SI{\pm 20}{\micro\meter}$;
(2) automobile engine, the clearance between the piston pin and hole is around $\SI{2.5}{\micro\meter}$ to $\SI{7.5}{\micro\meter}$. 
%DIF < (3) rv reducer, the clearance between the eccentric shaft and the bearing is $\SI{-20}{\micro\meter}$ to $\SI{-10}{\micro\meter}$~(which belongs to interference fit, meaning that $r_e > r_b$, where $r_e$ refers to the radius of the eccentric shaft and $r_b$ refers to the radius of the hole on the bearing). 
However, for these days, the positioning repeatability of the most accurate 6-DoF (Degree of Freedom) robotic manipulator is $\pm\SI{10}{\micro\metre}$ to $\pm\SI{30}{\micro\metre}$ for lightweight ($\le\SI{6}{\kilogram}$) applications.
Therefore, it is impossible to meet the precision requirement of these tasks for current robotic systems, \DIFdelbegin \textit{\DIFdel{relying on the precision of the manipulator itself}}%DIFAUXCMD
\DIFdel{. 
Aiming at solving }\DIFdelend \DIFaddbegin \DIFadd{relying on the precision of the manipulator itself. 
Aiming to solve }\DIFaddend this problem, methods and strategies are needed to help improve the precision of the robotic system.

In fact, to achieve high precision in robotic manipulation, the focus is on how to eliminate the uncertainty in the object, the robot, and the environment. 
In general, there are two solutions to this:
\DIFdelbegin \DIFdel{:
}\DIFdelend \begin{itemize}
    \item \textbf{Utilize sensors to perceive the state information between the robot and the object, establish a mapping relationship between the sensing information to manipulation strategies, to form robot control or learning algorithms.}

    \item \textbf{Utilize the constraint relationship between the robot and the object, which is formed by structure, shape, etc., to compensate the uncertainty during the manipulation process.}
\end{itemize}

Meanwhile, a natural problem will arise: does \DIFdelbegin \DIFdel{there exist }\DIFdelend a solution which could integrate the sensing information and the passive constraint \DIFaddbegin \DIFadd{exist}\DIFaddend ? It is known that \DIFdelbegin \DIFdel{human }\DIFdelend \DIFaddbegin \DIFadd{humans }\DIFaddend can finish very challenging high-precision manipulation tasks~\cite{Wu2015}. 
Although the human musculoskeletal system suffers from signal-dependent noise, which results in relatively low repeatability of manipulation performance, it can still meet the requirement in tasks where high-precision is needed. Related work on transferring these characteristics to robotic systems will also be discussed in this survey.

\begin{figure}
    \centering
    \DIFdelbeginFL %DIFDELCMD < \includegraphics[width=0.85\linewidth]{figures/schematic}
%DIFDELCMD <     %%%
\DIFdelendFL \DIFaddbeginFL \includegraphics[width=0.75\linewidth]{figures/schematic}
    \DIFaddendFL \caption{The categories of methods for high-precision robotic manipulation. 
    1. Sensing information based methods; 
    2. Compliant mechanism/device based methods;
    3. Environmental constraints based methods;
    4. Sensing-constraint integrated methods;
    5. Human-inspired methods.}
    \label{fig:schematic}
\end{figure}

Based on the above discussion, this paper will provide a brief survey for high-precision robotic manipulation in five aspects. 
Figure~\ref{fig:schematic} shows a schematic which illustrates the \DIFdelbegin \DIFdel{difference }\DIFdelend \DIFaddbegin \DIFadd{differences }\DIFaddend among the five groups of approaches. In the robotic manipulation, the \textit{subject} is the robot arm and hand, and the \textit{object} is the environment and the manipulated object. 
The \DIFdelbegin \DIFdel{dash }\DIFdelend \DIFaddbegin \DIFadd{dashed }\DIFaddend line represents the sensing information and the loop represents an up-to-date state perceived by sensors. 
For sensing information based methods, the inputs come from \DIFaddbegin \DIFadd{the }\DIFaddend sensor of every element of the system\DIFdelbegin \DIFdel{; }\DIFdelend \DIFaddbegin \DIFadd{. 
}\DIFaddend For compliant mechanism/device based methods, some additional parts are attached or embedded into the subject\DIFdelbegin \DIFdel{; }\DIFdelend \DIFaddbegin \DIFadd{.
}\DIFaddend For environment constraints based methods, the intrinsic knowledge of the system is used to the maximum extent\DIFdelbegin \DIFdel{; }\DIFdelend \DIFaddbegin \DIFadd{. 
}\DIFaddend For sensing-constraint integrated methods, the information from sensors and constraints from the environment are considered in the same framework\DIFdelbegin \DIFdel{; }\DIFdelend \DIFaddbegin \DIFadd{. 
}\DIFaddend For human-inspired methods, every element in the system learns from \DIFdelbegin \DIFdel{human }\DIFdelend \DIFaddbegin \DIFadd{humans }\DIFaddend for better performance.

The rest of this paper is arranged as follows. 
In Section~\ref{sec:compliant_sensor}, the work on sensing information based high-precision robotic manipulation will be presented. 
In Section~\ref{sec:compliant_dev}, the work on compliant mechanism/device based high-precision robotic manipulation will be explained. 
In Section~\ref{sec:compliant_env}, the work on environmental constraints-based high-precision robotic manipulation will be reviewed. 
In Section~\ref{sec:compliant_integration}, the work sensing-constraint integrated high-precision robotic manipulation will be reviewed. 
In Section~\ref{sec:compliant_advanced}, the work on human-inspired high-precision robotic manipulation will be introduced. The discussion and conclusion of the survey are given in Section~\ref{sec:discuss}.

\section{Sensing information based high-precision robotic manipulation}
\label{sec:compliant_sensor}

A sensor is a device that can feel the detailed measurement and then convert it to \DIFaddbegin \DIFadd{a }\DIFaddend usable output signal according to certain rules. It is a bridge for the robot to perceive the external environment. Therefore, sensing information plays an essential role in robotic manipulation.

Typical sensors used in robotic manipulation tasks include the visual sensor, the range sensor, and the force/torque sensor. In this section, \DIFdelbegin \DIFdel{we will briefly introduce }\DIFdelend the research of sensing information-based high-precision robotic manipulation \DIFaddbegin \DIFadd{will be briefly introduced}\DIFaddend . For each sensor, the characteristics will be discussed first. Then, the primary methods for using the sensor in high-precision robotic manipulation will be reviewed.

\subsection{Visual Sensors in High-precision Robotic Manipulation}
\label{subsec:visual_sensor}

Vision provides the most abundant information for the human. Eyes obtain nearly \SI{80}{\percent} to \SI{90}{\percent} of external data. Similarly, the visual sensor plays a vital role in robotic manipulation. 

\textbf{First}, the vision sensor can be used for target recognition and pose estimation. 

By installing the visual sensor in the hand of the robot (eye-in-hand), or fixing it in the workspace (eye-to-hand), the local or global scene information is extracted from images. 
Numerous computer vision algorithms are used for robotic manipulation tasks, especially for grasping~\cite{Morales2006,RecatalA2008,Speth2008,Su2009,Kobayashi2015,Ortenzi2018,Hu2019}. 
In these works, the edge of the object is first extracted and then the pose estimation problem is transferred to a graph matching problem.

In recent years, deep neural networks have made remarkable progress in the field of computer vision, and have attracted the attention of some robotic manipulation researchers. 
Girshick et al. and Ren et al. use R-CNN and Faster R-CNN to object detection for manipulation respectively, and the recognition rate is significantly improved~\cite{Girshick2014Rich,ren2017faster}. 

However, for robotic manipulation, it is not only necessary to know \textit{what} the object is, but also to know exactly \textit{where} (position and orientation) it is. It is still difficult for the mainstream convolution neural network to \DIFdelbegin \DIFdel{accurately }\DIFdelend \DIFaddbegin \textit{\DIFadd{accurately}} \DIFaddend identify the position and orientation of objects.

\textbf{Second}, the vision sensor can be used for measuring and positioning. 

Based on the principle of parallax of the binocular or multi-eye vision system, the position and orientation of the target object are calculated. 
For application in robotic manipulation, 
Sumi et al. developed a segment-based \DIFdelbegin \DIFdel{stereos }\DIFdelend \DIFaddbegin \DIFadd{stereo }\DIFaddend vision method based on the Versatile Volumetric Vision (VVV) system~\cite{Tomitaa1998}, which can measure and track the position and orientation of objects with curved surfaces~\cite{Sumi2002Object}.
Agrawal et al. proposed a complete visual guided robot system, which can be used for 3D pose estimation for known objects, to grasp 3D objects effectively~\cite{Agrawal2009Vision}. 
Chang et al. installed and tested a high-precision visual servo micro-assembly system, which can realize micro peg-hole alignment and micro peg-hole assembly~\cite{Chang11}.

\DIFaddbegin \DIFadd{Again, for robotic manipulation, it is important to make sure the measurement is of high precision. For visual sensors, the lens, the imaging sensors, the calibration of intrinsic/extrinsic parameters all exert a strong influence on the precision of the measurement. Around these topics there are active discussions about how to correct for lens distortion, how to filter out noisy points, and how to extract the camera parameters with the least effort. The relationship between the light and the texture of the objects should also be taken into consideration, since the reflection, shadow and occlusion will cause the extraction of the edge of the object to fail. Contrary to the above work, some researchers focus more on the task execution system to lower the requirement of for the sensors. This topic will be discussed in Section~\ref{sec:compliant_dev}.
}

\DIFaddend \textbf{Third}, some recent work attempts to minimize human participation during the robotic manipulation process. 

In this work, visual information is taken as raw input to train the robot for end-to-end, goal-oriented manipulation tasks.
To achieve this, \DIFdelbegin \DIFdel{some researchers first collected sufficient data from }\DIFdelend \DIFaddbegin \DIFadd{the researchers first need to collect sufficient data for the }\DIFaddend robot manipulation tasks. 
They studied how to effectively label and \DIFdelbegin \DIFdel{preprocess }\DIFdelend \DIFaddbegin \DIFadd{pre-process }\DIFaddend such data. Various data sets for robot task learning appeared in recent years. 
For example, 
Bullock et al. provided a data set for studying people’s grasping actions. They recorded the grasping actions in home and factory environments, and manually marked different grasp types, objects, and task parameters~\cite{Bullock2015}. 
Cai et al. designed the UT grasping dataset. The dataset consists of four different subjects, where they were asked to grasp a series of objects in a controllable environment (in front of the desktop) after telling them how to act~\cite{Cai2015scalable}.

Then, the researchers studied how to make a robot to adapt quickly to task changes, which means that the robot should be able to promptly re-plan its path to fulfill the new task requirement. 
Krabbe et al. proposed an interval estimation optimization algorithm based on the fusion of support vector machine (SVM) and principal component analysis (PCA) to train the robot terminal motion parameters and plan the motion trajectory based on the experimental data ~\cite{Krabbe2014Autonomous}. 
Berczi et al. have carried out the research of autonomous robot grasping based on deep learning. Through the training of grasping modes, the robot can reliably grasp different kinds of daily necessities such as \DIFaddbegin \DIFadd{a }\DIFaddend water cup, key, eyeglass box and book~\cite{Berczi2015Learning}. 
Li et al. implemented a skill-acquisition method based on deep reinforcement learning for a low-voltage apparatus assembly~\cite{Li2019}\DIFdelbegin \DIFdel{. They }\DIFdelend \DIFaddbegin \DIFadd{, where they }\DIFaddend achieved a success rate of \DIFdelbegin \DIFdel{around }\DIFdelend \DIFaddbegin \DIFadd{nearly }\DIFaddend \SI{80}{\percent}.

Concluded from current works, the existing robot learning methods need large sample data, and the \DIFaddbegin \DIFadd{coverage and size of the sample data have a high impact on the learning performance. But the }\DIFaddend process of acquiring a manipulation data is very time-consuming and laborious\DIFdelbegin \DIFdel{, and the coverage and size of the samples have a high impact on the learning performance}\DIFdelend \DIFaddbegin \DIFadd{.
Currently there are discussions on how to learn from a smaller dataset~\mbox{%DIFAUXCMD
\cite{Xu2018a,NIPS2017_6709}}\hspace{0pt}%DIFAUXCMD
, how to improve the learning efficiency~\mbox{%DIFAUXCMD
\cite{Levine2017}}\hspace{0pt}%DIFAUXCMD
, and how to train the robot in the simulation and adapt it to the real world without additional adjustments~\mbox{%DIFAUXCMD
\cite{Chebotar2018}}\hspace{0pt}%DIFAUXCMD
}\DIFaddend . It also remains an open \DIFdelbegin \DIFdel{problem }\DIFdelend \DIFaddbegin \DIFadd{topic }\DIFaddend on how to improve the precision from learning-based robotic assembly tasks \DIFaddbegin \DIFadd{while preserving its ability of generalization}\DIFaddend .

Besides, some scholars are trying to establish new frameworks or networks for specific tasks. 
Rodriguez proposes an “abort and retry” mechanism for robot grasp learning. Once the grasping failure is determined, a new experimental process is initiated immediately, which effectively shortens the training time of the robot platform learning algorithm~\cite{Rodriguez2011}. 
They also proposed an analysis method based on force signature, that is, to establish the distance function of \DIFaddbegin \DIFadd{the }\DIFaddend force signature between the new manipulation process and the successful manipulation process to quickly detect the failure occurred in the assembly process~\cite{Rodriguez2010}.
Lin et al. proposed a framework to learn the movement and force of a robot from human teachers. First, they estimated the contact force and position of the fingertips based on the changes in skin color when the fingertips were under pressure. The force and motion trajectory of the manipulation process is obtained by using Gaussian mixed regression, which is further used to control the robotic hand in real time~\cite{Lin2012}.
Paolini et al. established a general framework based on statistics for post-grasp manipulation. Instead of directly modeling the performance evaluation of action as a function of sensor observations or projecting sensor inputs into a more compact state representation, they encapsulate uncertainty through belief states. Thus, the system uncertainty caused by noisy sensors can be solved most effectively~\cite{Paolini2014}. 
Lenz et al. used the RGB-D sensor to recognize the position and orientation of the daily necessities based on the deep learning method, thus avoiding the time-consuming process of manually designing the features. They developed a two-step cascade network that followed a coarse-to-fine pattern of recognition, thus accelerating the recognition process~\cite{Lenz2015}.
Fischinger et al. proposed an unknown object capture method based on point cloud information. In their work, the point cloud data is used to extract the accumulative height feature of the objects in the presence of stacking and clutter, which can then be used to identify the topological structure of the object and select the grasping position~\cite{Fischinger2015}. 
Paulius et al. studied the functional object-oriented network, which is used to model the connectivity of objects related to function and the movement of objects in operation tasks~\cite{Paulius2016}. 


Ken Goldberg's group has recently done a series of work on robot grasping, given some prior information. 
They proposed Dex-Net, which is short for \DIFdelbegin \DIFdel{dexterity network}\DIFdelend \DIFaddbegin \DIFadd{`Dexterity Network'}\DIFaddend , a database and algorithm package for grasping daily objects.
In Dex-Net 1.0, Mahler et al. designed a network which outputs optimal grasping points for a given object. 
First, they collected more than 10000 \DIFdelbegin \DIFdel{3d }\DIFdelend \DIFaddbegin \DIFadd{3D }\DIFaddend object models. Based on that, they extracted the grasping points for each object by analytical methods. Then they trained the multi-angle convolution neural network (MV-CNN). When a new object appears, the most similar objects in the database will be found quickly, and the score of each grasping point for this object will be calculated based on the most similar object in the database~\cite{Mahler2016}.
In Dex-Net 2.0, they trained grasp quality convolution neural networks (GQ-CNN). The image and point cloud data are set as input, to predict the optimal candidate points for the possible grasping points for the object by calculating the probability~\cite{Mahler2017a}.
In their further work, they \DIFdelbegin \DIFdel{achieves better }\DIFdelend \DIFaddbegin \DIFadd{achieved a greater }\DIFaddend success rate in \DIFaddbegin \DIFadd{the }\DIFaddend universal picking problem by upgrading to an `ambidextrous' grasping system and training on synthetic datasets using domain randomization with analytic models of physics and geometry~\cite{Mahler2018,Mahler2019}. \DIFaddbegin \DIFadd{The proposed policy consistently clears bins of up to 25 novel objects with reliability greater than \mbox{%DIFAUXCMD
\SI{95}{\percent} }\hspace{0pt}%DIFAUXCMD
at a rate of more than 300 mean picks per hour. }\DIFaddend It would be a favorable direction if the work could be extended to high-precision manipulation.

\begin{figure}
    \centering
    {
        \subfloat[] {
            \label{subfig:camera}
            \includegraphics[width=0.2\linewidth]{figures/camera}}
        \hfil
        \subfloat[] {
            \label{subfig:range_sensor}
            \includegraphics[width=0.2\linewidth]{figures/range_sensor}}
        \hfil
        \subfloat[] {
            \label{subfig:force-torque}
            \includegraphics[width=0.2\linewidth]{figures/force-torque}}
        \hfil		
        \subfloat[] {
            \label{subfig:tactile}
            \includegraphics[width=0.2\linewidth]{figures/tactile}}
    }
    \caption{Typical sensors applied in robotic manipulation tasks.~(a) vision sensor.~(b) range sensor.~(c) force/torque sensor.~(d) tactile sensor.}
    \label{fig:sensors}
\end{figure}

\subsection{Range Sensors in High-precision Robotic Manipulation}
\label{subsec:range_sensor}

A range sensor refers to those used to sense the distance between the target point and the sensor. 
Range sensors are categorized as single-dot sensors, linear sensors and matrix array sensors depending on how much sensing units there are and how \DIFdelbegin \DIFdel{to arrange them}\DIFdelend \DIFaddbegin \DIFadd{they are arranged}\DIFaddend .
Due to the difference in measurement principles, they acquire the data by methods such as stereo triangulation, sheet of light triangulation, structured light, time-of-flight, interferometry, coded aperture measurement and so on.

Several commonly used range sensors in robotic manipulation tasks are listed as below: 
(a) \textit{Laser range sensor}, which can quickly and precisely extract the distance between the sensor and the target~\cite{Aleotti2014,Fur2018}. The main disadvantage is its high cost. 
(b) \textit{Stereo camera}, which captures images using two cameras and calculates the distance with the matching algorithm or triangulation measurement~\cite{Hu2016,Zhang2017,Pachtrachai2018,Deniz2018}. \DIFdelbegin \DIFdel{. }\DIFdelend It has moderate hardware complexity\DIFaddbegin \DIFadd{, }\DIFaddend but requires high computation complexity\DIFaddbegin \DIFadd{. }\DIFaddend Such sensors do not work appropriately in weak light or with unclear image features. 
(c) \textit{Structured-light sensor}, which emits controllable structured light to objects and extracts the parameters of the object by calculating the deformation of the light~\cite{Yang2017,Tran2017,Wieghardt2017,Anwar2017,Yu2018}. The advantage of structured light is that it \DIFdelbegin \DIFdel{does not need to change according to the change of the }\DIFdelend \DIFaddbegin \DIFadd{is independent from the }\DIFaddend scene, which lowers the difficulty of matching. The disadvantage is the interference of multiple sensors, and the sensor does not work in intense light. 
(d) \textit{Time-of-flight camera}, which sends light \DIFdelbegin \DIFdel{pulse }\DIFdelend \DIFaddbegin \DIFadd{pulses }\DIFaddend continuously and receives the light returned from the object to get the distance by \DIFdelbegin \DIFdel{counting }\DIFdelend \DIFaddbegin \DIFadd{recording }\DIFaddend the travel time of the light~\cite{Pan2016,Santos2018,Du2018,Lin2018,Han2018}. Similar to (a), such sensors have good precision and robustness. The high deployment price is the main disadvantage for now.

The range sensor is used in the robotic manipulation for object measurement and pose estimation. 
Jang et al. used stereo triangulation to realize 3D modeling of target based on "eye-in-hand" stereo cameras. They presented an analytical method to judge the local and global reachability of a given object in real environment~\cite{Jang05}. 
Based on the 3D laser scanner, Wang et al. proposed a method of modeling and grasping \DIFaddbegin \DIFadd{an }\DIFaddend a priori unknown object~\cite{Wang05}. 
Based on the linear structured light vision sensor, Xue et al. reported a two-step method to locate the center of the circular hole. 
The absolute accuracy of the sensor for measuring the radius of a circular hole in space is increased to \SI{0.08}{\milli\meter}, and the relative accuracy is better than \SI{1.6}{\percent}~\cite{Xue2008}.

For \DIFaddbegin \DIFadd{numerous }\DIFaddend applications, the range sensor is becoming a typical setup for a robotic manipulation system. \DIFdelbegin \DIFdel{The open problems include how to }\DIFdelend \DIFaddbegin \DIFadd{Due to the similarity between the visual sensors and range sensors, there are also many concerns on how to eliminate the side effects of the noise, how to }\DIFaddend adapt the sensor to a broader range of lighting situation, how to simplify the process of registration, and how to increase the accuracy of object pose recognition. \DIFaddbegin \DIFadd{It is also meaningful to reduce the response time for the real-time control.
}\DIFaddend 

\subsection{Force Sensors in High-precision Robotic Manipulation}
\label{subsec:force_sensor}

In the robotic manipulation task, the force/torque information is widely used to eliminate the small pose error in the parts. 
Figure \ref{subfig:force-torque} and \ref{subfig:tactile} show the force sensors commonly used in robot operations, including a six-axis force/torque sensor and a tactile sensor. 
The former is typically installed at the joints and wrists of the robot. It senses the force and torque on the object with its rigid connection; the latter is mainly established in the mechanical fingertips or palms. It senses the positive pressure on the corresponding mechanical part.

\subsubsection{Joint torque sensor}

These sensors are installed on the joints of the robot to obtain the torque information during the motion of the robot. 
On the one hand, the joint torque is used to identify the contact relationship between the robot and the object.
On the other hand, the joint torque information is often used in the compliance control of the manipulator. 
Jakovljevic et al. proposed an assembly method using fuzzy inference machine (FIM), which can quickly infer the current contact state according to the contact information in the assembly process~\cite{Jakovlijevic14}. 
Gaz et al. utilized the joint torque data to identify the dynamic model of the KUKA LWR robot (Light Weight Robot), which will further be used for investigating force control algorithms~\cite{Gaz2014}.
Bicchi et al. proposed a method to realize the intrinsic safety of the compliant manipulator. 
Based on the joint torque information, a compliance controller \DIFdelbegin \DIFdel{is }\DIFdelend \DIFaddbegin \DIFadd{has been }\DIFaddend designed, which can adjust the compliance of the end-effector when the mechanical impedance of the joint is unknown~\cite{Bicchi2001}. 
In their subsequent work, the active compliance control algorithm and the passive compliance mechanism are fused to achieve better safety in human-robot \DIFdelbegin \DIFdel{interaction }\DIFdelend \DIFaddbegin \DIFadd{interactions }\DIFaddend on the tendon-driven manipulator platform~\cite{Schiavi2009}. 
Santina et al. designed a balanced feedforward and feedback controller using joint force information to realize human-like motion by iterative learning control~\cite{Della2017}.

The primary focus \DIFdelbegin \DIFdel{on }\DIFdelend \DIFaddbegin \DIFadd{of }\DIFaddend this topic is how to design a more effective controller to achieve force control and compliant motion. \DIFaddbegin \DIFadd{Related topics include how to identify the system paramters with the sensors, and how to get the expected motion/interaction with noisy force signals. 
}\DIFaddend There are also efforts on extracting joint torque data from the characteristics of the mechatronic system, which will be further discussed in Section~\ref{sec:compliant_env}.

\subsubsection{Wrist force/torque sensor}

A wrist sensor is mounted on the robot's wrist to obtain force/torque information. 
Similar to joint torque sensors, the wrist sensor is either used for determining the contact state between the robot and the object~\cite{Garcia2009,Garciaa,Choi2015}, or for identifying the inertial parameters of the robotic manipulation system~\cite{Villani2000,Du2018a}.
Such sensors have been extensively studied for a long time, and many of them have been used in high-precision manipulation tasks, such as peg-in-hole assembly.
Xiao et al. proposed a method to accurately identify the contact state under the condition of position/orientation uncertainty by using the force/torque information~\cite{Xiao1998}. 
Kim et al. realized a quasi-static analysis method based on force/torque sensing information, which can be adjusted effectively when the robot encounters large directional error~\cite{Kim1999}.
De Carli et al. designed a human-robot cooperation system which does not involve \DIFdelbegin \DIFdel{grammar interaction using the }\DIFdelend \DIFaddbegin \DIFadd{verbal interaction with the robot.
Using the }\DIFaddend wrist six-axis force/torque sensor and the joint encoder information\DIFdelbegin \DIFdel{. 
They used the above information to }\DIFdelend \DIFaddbegin \DIFadd{, they }\DIFaddend identify the cooperative's conscious contact with the robot, and \DIFdelbegin \DIFdel{to change its }\DIFdelend \DIFaddbegin \DIFadd{then change the robot's }\DIFaddend direction in real time\DIFdelbegin \DIFdel{. 
Through the design of the impedance controller, the compliant action of human-robot contact is realized}\DIFdelend ~\cite{De2009}. 
Shirinzadeh et al. synthesized the information of force and torque, which can effectively identify the contact state of the cylindrical hole, and design a strategy to realize the minimum contact force in the process of shaft insertion~\cite{Shirinzadeh11Hybrid}. 
Ajoudani et al. combined the human-like impedance control with the minimum effort control to realize the human-like compliant assembly task~\cite{Ajoudani2013}. 
Kim et al. proposed an algorithm for part shape recognition and hole position detection based on \DIFaddbegin \DIFadd{a }\DIFaddend six-axis wrist force/torque sensor~\cite{Kim14}. 
Luo et al. proposed a new method based on geometric analysis, which is suitable for a 7-DOF industrial robot with a force/torque sensor. 
This method can simultaneously obtain the position and orientation information of the axis by a single search, and the Kalman filter with fuzzy logic can be used in the controller to realize admittance control~\cite{Luo2017}.
\DIFaddbegin \DIFadd{Xu et. al designed a MEMS microgripper with a dual-axis force sensor on its wrist~\mbox{%DIFAUXCMD
\cite{Xu2015,Xu2017}}\hspace{0pt}%DIFAUXCMD
. Due to the scale of the targeted system, they utilized comb-drive mechanism to realize the actuator and sensor, which provides a wide-range gripper with scale-variable precisions. Xu also developed a discrete-time sliding mode generalized impedance control with adaptive switching gain, which helps to control the position and force of the gripper simultaneously~\mbox{%DIFAUXCMD
\cite{Xu2013}}\hspace{0pt}%DIFAUXCMD
.
}\DIFaddend 

Since the force/torque information is local and transient in the assembly process, \DIFdelbegin \DIFdel{basically }\DIFdelend it is difficult to acquire any global or absolute conclusion, without much prior knowledge of the object and the system. 
There \DIFdelbegin \DIFdel{are also interests }\DIFdelend \DIFaddbegin \DIFadd{is also an interest }\DIFaddend in how to balance the contradiction between accuracy and sensitivity~\cite{Sun2015,Miyashita2018}, and how to achieve \DIFaddbegin \DIFadd{an }\DIFaddend efficient switch between various contact/non-contact states~\cite{Zhang2013,Gracia2018}.

\subsubsection{Palm and fingertip tactile sensors} 

Tactile sensors are mounted at the end of the palm or finger to obtain contact force or pressure. 
They are typically used for contact state identification~\cite{Chu2018,Pirozzi2018,Abdeetedal2018a}, for friction estimation~\cite{Howea,Cutkosky1986,Montano2018}, or for slippage detection during grasping~\cite{Schuermann2012,Wong2016,Rana2016,Motamedi2017,Veiga2018}.
To solve the grasping problem, Cutkosky et al. worked on a lot of fundamental work on \DIFaddbegin \DIFadd{a }\DIFaddend grasping contact model~\cite{Cutkosky1986,Cutkosky1989,Cutkosky1989a,Howe1993}.
Shimoga et al. conducted a series of research on \DIFdelbegin \DIFdel{grasping modeling }\DIFdelend \DIFaddbegin \DIFadd{a grasping model }\DIFaddend with soft robotic fingers~\cite{Shimogaa,Shimoga1996,Shimoga1996a}. 
Sun designed a fingerprint sensor integrated with fingertip force and torque detection. Using this sensor, high precision contact force and contact spatial information can be obtained simultaneously~\cite{Sun2011}.
Lin et al. realized a strategy of grasping three-dimensional deformable objects by robotic hand. 
With \DIFaddbegin \DIFadd{a }\DIFaddend tactile sensor, a virtual traceability test algorithm is designed to detect whether the object can be effectively lifted before grasping~\cite{Lin2015a}. 
Koval et al. used the contact sensor mounted on the dexterous hand to estimate the position and orientation of the plane object with high accuracy and high speed. 
They also studied the real-time closed-loop feedback using tactile sensors to solve the problem of planar object operation under uncertainty~\cite{Koval2015}. 
Krug et al. designed an algorithm to analyze the success rate of grasping using tactile information as feedback~\cite{Krug2016}. 
Prattichizzo et al. discussed the controllability of motion and force for BarrettHand and human-inspired robotic hand, and for the problem of fine grasping predisposition. By analyzing the finger tip force and torque, a design method was proposed to improve the efficiency and reliability of grasping and reduce the complexity of the hand~\cite{Prattichizzo2013}.

It is a trend to employ artificial intelligence to analyze the information obtained from tactile sensors.
Particularly, extreme learning machine (ELM) is applied to tactile sensing systems for object recognition tasks ~\cite{Liu2017,Zhang2018,Liu2019}.
Lee et al. designed a replacement of \DIFaddbegin \DIFadd{an }\DIFaddend existing tactile sensor through the visual and electric information~\cite{Lee2018}. They combined a recurrent neural network (RNN) with a long short-term memory (LSTM) network to recognize the change pattern of deformable and undeformable objects.
Veiga et al. applied supervised learning to the prediction of the future occurrence of slip during grasping~\cite{Veiga2018}.
Eguiluz et al. proposed a recursive multimodal tactile material identification approach~\cite{Eguiluz2018}.

\DIFaddbegin \DIFadd{There is work on implementing new force sensors for the palms and fingertips. 
}\DIFaddend The major focus on this field also includes how to implement tactile sensor with high resolution, high sensitivity, and \DIFdelbegin \DIFdel{high response speed}\DIFdelend \DIFaddbegin \DIFadd{short response time}\DIFaddend ~\cite{Yin2018,Patel2018,Boutry2018,Hughes2018,Zhang2018}.

\section{Compliant mechanism/device based high-precision robotic manipulation}
\label{sec:compliant_dev}

In mechanical engineering, compliant mechanisms are flexible mechanisms that transfer or transform motion, force or energy through elastic body deformation rather than from movable joints only.
Using a compliant mechanism/device can lead to a passive compliant motion of the robot arm, which allows the pose error between the assembly parts to be eliminated during such movement.
Compared with the sensor-based method, this method makes use of the relationship between the geometry and the mechanical structure between the object and the robot system, providing a certain degree of compliance for a specific manipulation task. 
Typical equipment and devices include remote compliance center device (RCC), variable stiffness actuator (VSA) and so on.

\subsection{Remote Center of Compliance (RCC)}
\label{subsec:rcc}

Remote Center of Compliance (RCC) has been invented by Whitney~et al. to help accomplish insertion and assembly tasks~\cite{Whitney1986a}. 
In their research, they extensively discussed the robotic insertion process~\cite{Whitney1987}.
\begin{figure}[htb]
    \centering
    \includegraphics[width=0.99\linewidth]{figures/rcc}
    \caption{The general mechanical structure of an RCC device.}
    \label{fig:rcc}
\end{figure}
During the insertion process, the peg will tend to rotate about an axis in the plane of the gripper's fingers, which is called the center of compliance. 
As shown in Figure~\ref{fig:rcc}, the RCC device is in fact an elastic mechanism with 6 DoFs (\DIFdelbegin \DIFdel{degree }\DIFdelend \DIFaddbegin \DIFadd{degrees }\DIFaddend of freedom), which could change the position of the center of compliance of the system.


Since invention, there have been many variants of \DIFaddbegin \DIFadd{the }\DIFaddend RCC. 
Kazerooni~et al. developed an active compliant end-effector (Active RCC) with electronic compliancy (the impedance of the system could be changed by computer)~\cite{Kazerooni1988}. The structure was very complex so that it could not be widely applied to practical application.
Joo and Lee separately analyzed the limitations of RCC and proposed some designs for variable RCC (VRCC)\cite{Joo1998, Lee2005}, which could vary the center of compliance of the RCC by adjusting some elements of the device (such as a knob).
Dubois et al. designed a universal joint with a lower mobility remote center compliance linkage~\cite{Dubois2016}.

Although RCC is the most common solution in real application, it has several shortcomings: 
(1) \DIFdelbegin \DIFdel{there }\DIFdelend \DIFaddbegin \DIFadd{There }\DIFaddend has to be chamfer on the peg or the hole, which acts as the guidance for the peg to be inserted with RCC\DIFdelbegin \DIFdel{; }\DIFdelend \DIFaddbegin \DIFadd{. 
}\DIFaddend (2) For simplification of the design, \DIFaddbegin \DIFadd{the }\DIFaddend elastomer shear pad(ESP) was introduced by Whitney et al.~\cite{Whitney1986b}. However, with \DIFaddbegin \DIFadd{the }\DIFaddend ESP, the compliance center of the RCC is fixed so that different \DIFdelbegin \DIFdel{ESP }\DIFdelend \DIFaddbegin \DIFadd{ESPs }\DIFaddend must be used \DIFdelbegin \DIFdel{to }\DIFdelend \DIFaddbegin \DIFadd{for }\DIFaddend different lengths of the peg. 
(3) \DIFdelbegin \DIFdel{the }\DIFdelend \DIFaddbegin \DIFadd{The }\DIFaddend insertion direction has to be vertical since the RCC \DIFdelbegin \DIFdel{device }\DIFdelend \DIFaddbegin \DIFadd{devices }\DIFaddend are made up of elastic elements.

There are also some efforts on implementing vibration devices with RCC for the high-speed robotic manipulation task, especially for the peg-in-hole insertion task. 
Kilikevicius et al. investigated the insertion process using vibratory excitation for robotic assembly~\cite{Kilikevicius2007,Kilikevicius2011}. 
Baksys et al. designed several vibratory alignment systems for the peg-hole insertion task~\cite{Baksys2008,Baksys2011}. They further analyzed the relationship between alignment duration, initial pressing force, shape and excitation frequency~\cite{Baksys2010}. 
In their experimental setup, the system could realize a peg-hole insertion task with \DIFdelbegin \DIFdel{clearance \mbox{%DIFAUXCMD
\SIrange{0.05}{0.10}{\milli\meter} }\hspace{0pt}%DIFAUXCMD
}\DIFdelend \DIFaddbegin \DIFadd{\mbox{%DIFAUXCMD
\SIrange{0.05}{0.10}{\milli\meter} }\hspace{0pt}%DIFAUXCMD
clearance }\DIFaddend in \SIrange{70}{150}{\milli\second}.
However, how to find the most suitable vibratory frequency has not been reported in any work in this area.

\subsection{Variable Stiffness Actuator (VSA)}
\label{subsec:vsa}

Besides the classic passive device, especially the RCC and its variants, a new type of actuator, the variable impedance actuator (VIA) has been introduced to realize compliance to the environment (as shown in Figure~\ref{fig:vsa}), which introduces an elastic element with variable impedance between the gear and the actuator output~\cite{Wolf2016}.

\begin{figure}[htb]
    \centering
    \includegraphics[width=0.99\linewidth]{figures/vsa}
    \caption{Mass model of a 1-DoF VSA interacting with the environment.}
    \label{fig:vsa}
\end{figure}

Balletti et al. proposed a low-cost solution for peg-hole insertion with variable impedance actuators (VIA)~\cite{Balletti2012}. In the paper, the peg-in-hole assembly task was achieved by the CubeBot dual-arm platform. VIA actuators are equipped to both arms for compliant motion during the insertion process. With simple planning and control, the platform could achieve the task with \DIFaddbegin \DIFadd{a }\DIFaddend small contact force ($\le \SI{15}{\newton}$).
Bicchi et al. \DIFdelbegin \DIFdel{propose }\DIFdelend \DIFaddbegin \DIFadd{proposed }\DIFaddend a new actuator which incorporates the possibility to vary transmission stiffness during motion execution, thus allowing substantial motion speed-up while maintaining low injury risk levels~\cite{Bicchi2005}.
Santina et al. \DIFdelbegin \DIFdel{develop }\DIFdelend \DIFaddbegin \DIFadd{developed a }\DIFaddend `soft' robot based on \DIFdelbegin \DIFdel{VSA which balances }\DIFdelend \DIFaddbegin \DIFadd{the VSA which could balance the }\DIFaddend feedback and feedforward elements~\cite{Della2017}.
Readers are suggested to refer to~\cite{Wolf2016} for a detailed review of VIA.
Currently many prototypes of robot \DIFdelbegin \DIFdel{arm and hand }\DIFdelend \DIFaddbegin \DIFadd{arms and hands }\DIFaddend with VSAs in replace of stiffness motors are under development~\cite{Zheng2016,Rice2018,Haas2018}.

\section{Environmental constraints based high-precision robotic manipulation}
\label{sec:compliant_env}

In addition to using compliant mechanisms/devices to provide the compliance required for the robot to manipulate with high precision, there is a wide range of constraints, such as configuration constraints and force constraints, between the robot and the manipulated objects. 
With these constraints, it is possible to design effective manipulation strategy to guide the robot without the aid of a compliant mechanism/device when the sensing information is unknown or partially known to realize high precision manipulation. 
Related theoretical work mainly includes attractive region in environment (ARIE), caging and other methods.

%\subsection{Some preliminary works}
%\label{subsec:pre-work}
%To understand the environment, it is essential to understand both the subject (the robot arm and the robot hand) and object (the environment and the object) of the system. 
%At the beginning, many efforts were devoted to the implementation of an accurate gripper model~\cite{Cutkosky1989}.
%The works inspired a great many of later works, both in sensor-based methods and in environmental based methods.

\subsection{Attractive Region in Environment}
\label{subsec:arie}

The Attractive Region in Environment (ARIE) is a kind of constrained region formed by \DIFaddbegin \DIFadd{the }\DIFaddend environment, which exists in the configuration space of the robotic system.  

The concept of \DIFdelbegin \DIFdel{``attractive region in environment'' (ARIE ) }\DIFdelend \DIFaddbegin \DIFadd{ARIE }\DIFaddend was first proposed by Qiao~\cite{Qiao2000}. An analogous example is illustrated as below: Say there are an imaginary bean and an imaginary bowl in the physical space. If the initial position of the bean is above the upper surface of the bowl, under the effect of gravity and friction, the bean will drop into the bowl and finally stay at the bottom of the bowl.

Inspired by such phenomenon in physical space, the concept of ARIE is delineated as below: 
\DIFdelbegin \DIFdel{If }\DIFdelend \DIFaddbegin \DIFadd{if }\DIFaddend the bean represents the state of the system, and the bowl represents the environmental constraint, and if there exists a state-independent input, then the state of the system can converge to stable in the `bowl'. Such `bowl' is called the `Attractive Region in Environment'.

The concept is further discussed in~\cite{Qiao2002, Qiao2003} for achieving high-precision sensorless manipulation in production. Through a unique method of formulation and utilization of the attractive region in the configuration space, the strategy to attain high-precision assembly in physical space without \DIFaddbegin \DIFadd{a }\DIFaddend force sensor and flexible wrist was designed, and the approach to achieve 2D and 3D part orientation by sensor-less grasping and pushing actions was also provided (See Figure \ref{fig:arie}).



\begin{figure}[ht]
    \centering
    \includegraphics[width=0.99\linewidth]{figures/arie_demo}
    \caption{Two complex parts and their corresponding ARIE in $\mathbb{R}^3$ space.~\textit{Left}: contact states of the complex parts.~\textit{Right}: the corresponding points in ARIE.}
    \label{fig:arie}
\end{figure}


Based on this theory, several high-precision robotic manipulation tasks have been realized. For specific application areas, several methods have been developed based on ARIE. 
For example, for automobile manufacturing, 
Su et al. designed an eccentric peg-hole sensorless assembly system with ARIE-based strategy~\cite{Su2012a, Su2012b}. 
Su et al. developed a vision-based 3D grasping planning approach with one single image~\cite{Su2009}. 
Liu et al. composed a stable sensorless localization method for 3D objects with \DIFaddbegin \DIFadd{a }\DIFaddend simple pushing mechanism~\cite{Liu2011}. 
Liu et al. created a vision-based 3D grasping algorithm for grasping 3D objects with \DIFaddbegin \DIFadd{a }\DIFaddend simple 2D gripper~\cite{Liu2014}.
Li and Qiao reported an ARIE-based robotic strategy for general convex peg - convex hole insertion tasks~\cite{Li2017}.

In recent work, Qiao et al. discussed the definition and the generalized conditions of ARIE~\cite{Qiao2015}. In this work, the general mathematical description of ARIE was presented, and the condition of the existence of ARIE in different configuration space was analyzed. Notably, the relationship of the ARIE in \DIFdelbegin \DIFdel{high-dimensional space }\DIFdelend \DIFaddbegin \DIFadd{high- }\DIFaddend and low-dimensional space was discussed. The future work includes the integration with learning algorithms and the interaction with human motion mechanisms.


\subsection{Caging}
\label{subsec:caging}

The caging problem was originally proposed by Kuperberg as a problem of finding a set of placement of fingers that prevents a polygon from moving arbitrarily far from its given position~\cite{kuperberg1990problems}:
\DIFdelbegin %DIFDELCMD < 

%DIFDELCMD < %%%
\DIFdelend \DIFaddbegin \DIFadd{``}\DIFaddend Let $P$ be a polygon in the plane, and let $C$ be a set of $k$ points which lies in the complement of the interior of $P$. The points capture $P$ if $P$ cannot be moved arbitrarily far from its original position without at least one point of $C$ penetrating the interior of $P$. Design an algorithm for finding a set of capturing points for $P$.\DIFaddbegin \DIFadd{''
}\DIFaddend 

\DIFdelbegin \DIFdel{Later the }\DIFdelend \DIFaddbegin \DIFadd{The }\DIFaddend caging problem has been studied by many researchers. The concept and conditions for the caging problem have been growing in a series of mathematical works. 

It has also been found that the theory of caging can be applied to the robotic grasping area. 
Rimon et al. studied the relationship between caging configurations and grasp configurations~\cite{Rimon1999}. 
Rodriguez et al. analyzed the relationship between cages and grasps of a rigid body and proposed a method to use cages as way-points to form a stable grasp~\cite{Rodriguez2012b}. 
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.99\linewidth]{figures/caging}
    \caption{From pregrasping cage to grasping cage~\cite{Rodriguez2012b}.}
    \label{fig:caging}
\end{figure}
Wan et al. extended the work on grasping by caging with a solution which uses eigen-shapes to reduce the dimensionality of the dexterous hands, and space mapping to efficiently measure the robustness of caging~\cite{Wan2013}.
Egawa et al. realized both 2D and 3D caging-based grasping of objects of various shapes with circular robots and multi-fingered hands~\cite{Egawa2015}.
Su et al. discussed the relationship among caging configuration, form-closure grasp, and \DIFdelbegin \DIFdel{attractive region in environment (ARIE)}\DIFdelend \DIFaddbegin \DIFadd{ARIE}\DIFaddend , and proposed a vision-based caging grasp algorithm for \DIFaddbegin \DIFadd{a }\DIFaddend binary industrial gripper~\cite{Su2015a,Su2015b,Su2017}.
Lei et al. combined the advantage of caging and force closure grasping to enable different grippers to grasp unknown flat objects quickly~\cite{Lei2016}.
Kwok et al. present a caging grasp method inspired by ropes caging which can guarantee to generate local stable grasps~\cite{Kwok2016}.

The readers are suggested to refer to~\cite{Makita2017} for a recent survey of the research on caging grasp.

\subsection{Other Methods}
\label{subsec:extrinsic}

Other than the above-mentioned concepts, there still remain a large \DIFdelbegin \DIFdel{number }\DIFdelend \DIFaddbegin \DIFadd{amount }\DIFaddend of work on environmental constraint-based manipulation.
For example, 
Dafle et al. discovered that many in-hand manipulations rely on resources extrinsic to the hand, such as gravity, external contacts or dynamic arm motions. They referred to them as ``extrinsic dexterity'' and demonstrated that simple grippers are capable of ample in-hand manipulation~\cite{Dafle2014a, Dafle2014b}.
Ciocarlie et al. discussed the concept of low-dimensional posture subspace for dexterous hand and grasping~\cite{Ciocarlie2009}. In this work, `Eigen grasp' was defined as a vector in high-dimensional hand posture space, and the goal was to find an optimal subspace where a wide range of hand postures could be represented in it.
Takahashi et al. proposed an assembly technique based on passive alignment principle (PAP) for the deformable component, which achieved the compliance on the hand (loose grip) instead of on the wrist or joints of the robot arm (compliance control)~\cite{Takahashi2016Passive, Fukukawa2016}.
Park et al. presented a compliance-based peg-in-hole assembly strategy\DIFaddbegin \DIFadd{, }\DIFaddend which did not involve force/torque sensors or remote compliance mechanisms~\cite{Park2017}. The method analyzed the contact state of the peg-hole system and provided a strategy to overcome the initial positional error of the hole incurred in the recognition process.

In contrast to the sensor-based methods, some researchers investigate sensor-less methods. They \DIFdelbegin \DIFdel{are in an attempt to be out of the trouble of }\DIFdelend \DIFaddbegin \DIFadd{attempt to minimize the }\DIFaddend sensor noise, error, low precision, and cost~\cite{Erden2010,Pistillo2011,Yao2018}.
Bicchi and Marigo analyzed rolling contacts for dexterous manipulation and provided a result on the analysis of controllability of rolling pairs of bodies~\cite{Bicchi2000c}.
Zhang et al. studied the point contacts relationship between the gripper and planar polygons~\cite{Zhang2002}. An algorithm combining toppling, accessibility and form-closure analysis is implemented for part alignment.
Gabiccini et al. developed a grasp and manipulation analysis method for synergistic underactuated hands~\cite{Gabiccini2012}. A framework to model and study the structural properties of a grasp by a general robotic hand in a quasi-static setting was established.
Chen et al. presented an approach to \DIFdelbegin \DIFdel{recognizing }\DIFdelend \DIFaddbegin \DIFadd{recognize }\DIFaddend hand gestures accurately during an assembly task while in collaboration with a robot co-worker~\cite{Chen2015a}. The Hidden Markov Model (HMM) method was adopted to recognize patterns and assembly intentions.
\DIFaddbegin \DIFadd{Xu et. al designed a series of mechatronic systems with compliant constant-force mechanisms for grasping and other operation, which do not require a force/torque sensor for safe manipulation~\mbox{%DIFAUXCMD
\cite{Xu2018,Wang2018,Zhang2018}}\hspace{0pt}%DIFAUXCMD
.
}\DIFaddend 

The open problems under this topic include but are not limited to (a) how to obtain some values in sensor-less systems (modeling and control), (b) how to effectively utilize a given environment, and how to intentionally design a manipulation-favorable environment (strategy investigation and planning).

\section{Sensing-constraint integrated high-precision robotic manipulation}
\label{sec:compliant_integration}

As discussed in Section~\ref{sec:compliant_env}, there is intrinsic knowledge (in most cases, the geometrical relationship) within the robotic manipulation system and the objects to be manipulated. 
If such information is used, strategies should be more easily made based on the understanding of such knowledge. 
Also, it should be worth a try to combine the sensor-based method with the environmental constraint-based method, which would possibly benefit from both methods. 
In this section, some exploratory work will be introduced to show how sensing information and environmental constraint can be integrated from different spaces into a unified framework, and how such integration helps in the robotic manipulation.


\subsection{Constrained Region in Environment (CRIE)}
\label{subsec:crie}

As discussed in Section~\ref{sec:intro}, the integration of sensing information and environmental constraints is reasonable and should be paid more attention in \DIFaddbegin \DIFadd{the }\DIFaddend robotic manipulation area. 
As the first step of an attempt, the concept of `constrained region in environment' (CRIE) is proposed, which is \DIFdelbegin \DIFdel{hoped }\DIFdelend \DIFaddbegin \DIFadd{expected }\DIFaddend to bridge environmental constraints with sensing information. 
Li et al. discussed the compliance of robotic hands by analyzing the anatomical structure of the human hand and its control mechanism~\cite{Li2015}.
Ma et al. proposed a flexible robotic grasping strategy with the constrained region in environment which can adjust the grasping configuration according to the approximate contact force direction~\cite{Ma2017}. A new non-physical space was provided to combine the state space and sensing space.

The definition of the CRIE is described as below:
\begin{definition}
    For a general differential system, which can be characterized as $ \mathbf{X}=f(\mathbf{x}, \mathbf{u}) $, where $ \mathbf{x} \in \mathbb{R}^{p} $ is the state of the system and $ \mathbf{u} \in \mathbb{R}^{q} $ is the input to the system. $ \mathbf{x} $ can be observed by sensors with errors, that is, $ \mathbf{x}_{s}=\mathbf{x}+\delta\mathbf{x} $, and $ \mathbf{x} $ is constrained by a region $ \mathbf{\Omega} \subset \mathbb{R}^{p}$. If there exists an input $ \mathbf{u}=\mathbf{u}_{i}(\mathbf{\Omega})+\mathbf{u}_{d}(\mathbf{x}_{s}) $ and an $ \mathbf{\Omega} $-related scalar function $ g(\mathbf{x}) $ satisfying that
    \DIFdelbegin %DIFDELCMD < \begin{itemize}
%DIFDELCMD <         \item %%%
\DIFdelend \DIFaddbegin \DIFadd{(a) }\DIFaddend $ g(\mathbf{x}) > g(\mathbf{x}_{0}) $, for all $ \mathbf{x} \ne \mathbf{x}_{0} $, and $ g(\mathbf{x}) = g(\mathbf{x}_{0}) $, for $ \mathbf{x} = \mathbf{x}_{0} $\DIFdelbegin \DIFdel{;
        }%DIFDELCMD < \item %%%
\DIFdelend \DIFaddbegin \DIFadd{, and
    (b) }\DIFaddend $ g(\mathbf{x}) $ is smooth with respect to $ \mathbf{x} $,
    \DIFdelbegin %DIFDELCMD < \end{itemize}
%DIFDELCMD <     %%%
\DIFdelend then there exists a CRIE in the system.
\end{definition}

There are two functionalities for utilizing CRIE: 
(a) it serves as an implicit sensor to detect the current state of the system since the environmental constraints refine and reveal some states;
(b) it serves as an error detector since the sensing information exploits the difference of the ideal scene and the real scene.

\subsection{Tentative Improvement of Sensing Information based Methods}
\label{subsec:tentative}

Besides combining the sensing information and the environmental constraints in one space, there is much work on implementing tentative improvement on sensor-based methods or environmental constraint-based methods. Starting from one side, they try to improve the performance by adding the other option to the original work. 
For example, 
Rosales et al. studied the solution to the grasp synthesis problem, which consisted of finding the best hand configuration to grasp a given object for a specific manipulation task while satisfying all the necessary constraints~\cite{Rosales2012}.
Bicchi et al. researched \DIFdelbegin \DIFdel{on }\DIFdelend a modeling method for grasping and active touch by natural and artificial hands~\cite{Bicchi2011}.
They also studied the hand synergy problem, which integrated robotics and neuroscience for understanding the control of biological and synthetic hands~\cite{Santello2016}.
Schultz et al. showed a particular recruitment strategy for exploiting muscle-like actuator impedance properties~\cite{Schultz2015}.
Kiguchi et al. examined how a human being decides the grasping force necessary to manipulate an unknown object to apply a human object-grasping strategy for robotic systems~\cite{Kiguchi2003}.
Abdeetedal and Kermani designed a grasping system for picking fruits from trees~\cite{Abdeetedal2018}. Inspired by \DIFdelbegin \DIFdel{the human }\DIFdelend \DIFaddbegin \DIFadd{human biology}\DIFaddend , they introduced a method to measure the friction between the gripper and the object. With the knowledge of friction, the grasping system achieved the harvesting task with good generality.

In some way, some of these works can be understood as \DIFdelbegin \DIFdel{imitating human from behavior}\DIFdelend \DIFaddbegin \DIFadd{biomimetics}\DIFaddend . A further discussion is followed in the next section.

\section{Some New Trends on Robotic Manipulation}
\label{sec:compliant_advanced}

As described in the previous section, to improve compliance in robotic manipulation, one possible method is to learn from humans - a man can utilize the dexterity of his hands to achieve high-precision manipulations~\cite{Wu2015}. 
Although the movement of the hand is controlled by tendons and muscles attached to the bone, its structure and control mechanism can still provide some clues for improving the design and motion planning for existing robotic systems. 
Inspired by human hands, two possible but essential features are listed and discussed below, providing some inspiration for improving the robot system to meet the requirements for the manipulation task.
%(as shown in Figure~\ref{fig:humanpegholetask}).

%\begin{figure}
%    \centering
%    \includegraphics[width=0.7\linewidth]{figures/human_peg_hole_task}
%    \caption{The simulation of how human makes the peg-in-hole assembly task.}
%    \label{fig:humanpegholetask}
%\end{figure}

\begin{figure*}[h]
    \centering
    \includegraphics[width=0.95\linewidth]{figures/table04v3}
    \caption{The characteristic of each type of methods, in terms of the utilization of sensor, constraint and algorithm.}
    \label{fig:table02}
\end{figure*}

\subsubsection{Coupled, redundant structure of the robot end-effector}

There are 41 muscles in one human \DIFdelbegin \DIFdel{upper limb}\DIFdelend \DIFaddbegin \DIFadd{arm}\DIFaddend . 
Some of these muscles contract and relax simultaneously as a group to control one joint; on the other hand, each muscle is usually attached to multiple joints, thus affecting the motion of all the attached joints.
Due to the complexity and redundancy of the muscle-skeleton structure, the movement of a joint can be achieved by a different combination of muscles.
For example, if one muscle does not work `correctly', other muscles can compensate for the loss or error caused by that muscle. 
At present, most of the robot \DIFdelbegin \DIFdel{arm and hand }\DIFdelend \DIFaddbegin \DIFadd{arms and hands }\DIFaddend apply decoupling control. However, the motion of the hand is the superposition of each motor position in \DIFdelbegin \DIFdel{3d }\DIFdelend \DIFaddbegin \DIFadd{3D }\DIFaddend space. Therefore, the motion error is the superposition of each motor's error. 
If the robot end-effector can realize the coupling and redundant structure in an appropriate way, it may make the motion more compliant. 

In this regard, some researchers designed new robotic hands with tendon structure, which achieve better interaction with the target in an unknown environment. 
Bicchi et al. proposed a general framework for modeling a robot manipulation system with redundant tendon actuation and multilateral constraints. The optimal tendon tension was calculated by considering the force distribution in this framework~\cite{Bicchi2000d}. 
Shirafuji et al. developed a human-like robotic hand with tendon-driven fingers~\cite{Shirafuji2014}. 
The fingers of the hand mimicked two mechanisms of human fingers: 
(a) the fingers consisted of an equivalent actuator and the tendon arrangement of the human LU muscle\DIFdelbegin \DIFdel{.
}\DIFdelend \DIFaddbegin \DIFadd{, and
}\DIFaddend (b) the fingers realized a kind of double pulley mechanism, which may change the moment arm in a nonlinear manner based on the joint angle values.
Inouye et al. proposed a tendon-driven optimization method for robotic hands, which satisfied the given anatomical and design constraints. This method could optimize the design of the \DIFdelbegin \DIFdel{tendon driving }\DIFdelend \DIFaddbegin \DIFadd{tendon-driven }\DIFaddend structure to obtain the maximum force capacity~\cite{Joshua2014}. 
Rahman et al. designed a dexterous four-fingered gripper, each with four degrees of freedom, for in-hand manipulation. The main feature was the ability to release objects in an appropriate manner~\cite{Rahman2016}.

\subsubsection{Flexible control strategy} 
With the coupled and redundant structure of the arm and hand as mentioned above, \DIFaddbegin \DIFadd{a }\DIFaddend human learns to achieve high precision manipulations via flexible control strategies. In the following, two main control strategies are listed and discussed.
\begin{itemize}
    \item \textbf{Range from large to small:}

    To achieve flexible but precise movement, a human usually controls the arm and wrist at first to move the hand near the target position and then follows the movement of the fingers for later manipulation. This control strategy requires the system to have a rough idea of how precise the arm, wrist, and hand \DIFaddbegin \DIFadd{are}\DIFaddend , respectively. Moreover, the movement error of the arm and wrist could be compensated with proper control of the fingers. Inspired by such \DIFaddbegin \DIFadd{a }\DIFaddend control regime, the control of the robot hand could be adopted from a broad range to a narrow one.

    \item \textbf{Experience as the basis of control:}

    Due to the complex structure of the hands, human learns to control their hands mainly based on experience. In childhood, people spend years trying different ways to grasp objects and manipulate them. With such a long-term learning process, one person will have his habit of control of their hands, which is mainly stored in the cerebellum and spinal cord. Later, these habits could be applied and updated for later manipulations. Thus, if the coupled redundant structure is implemented in a robot hand, such control regime could also be employed. With the development of deep neural networks in recent years, the control strategies could be achieved via reinforcement learning and transfer learning. Based on these pre-trained neural networks, it is possible to control the robot hand in the desired way to achieve compliant manipulations.	
\end{itemize}

\section{Discussion \& Conclusion}
\label{sec:discuss}

In the above sections, five categories of methods for high-precision robotic manipulation have been reviewed. 
The characteristic of each type is concluded in Figure~\ref{fig:table02}.

To quantitatively compare the recent work, peg-hole insertion is selected as a case of manipulation and papers with performances are listed in Table~\ref{tab:comparison}.  
Since there are differences of robot platform, clearance of the object, material of the object and so on among these works, it is meaningless to \DIFaddbegin \DIFadd{declare }\DIFaddend which is better or worse. 
However, \DIFdelbegin \DIFdel{we may find }\DIFdelend some facts on this topic \DIFdelbegin \DIFdel{as below}\DIFdelend \DIFaddbegin \DIFadd{may be found as follows}\DIFaddend :
(a) \DIFdelbegin \DIFdel{For }\DIFdelend \DIFaddbegin \DIFadd{for }\DIFaddend robotic assembly, most of the works are based on sensing information, and few works are based on the integration of the sensing information and the environmental constraint. Human-inspired structure and control have yet been applied to assembly tasks\DIFdelbegin \DIFdel{. 
}\DIFdelend \DIFaddbegin \DIFadd{, and
}\DIFaddend (b) \DIFdelbegin \DIFdel{As }\DIFdelend \DIFaddbegin \DIFadd{as }\DIFaddend the increase of precision in both the sensors and the robotic manipulation systems, there is extensive attention on strategies to make assembly general and robust. Therefore, learning-based methods become a future trend to be more investigated. \DIFaddbegin \DIFadd{Lastly, 
}\DIFaddend (c) \DIFdelbegin \DIFdel{Compliant }\DIFdelend \DIFaddbegin \DIFadd{compliant }\DIFaddend mechanism/device is very useful in some specified assembly tasks, where a frequent change to assembly objects is not made. This limits their range of applications. It would be a reasonable attempt to combine these methods with other methods.

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
% \usepackage{multirow}
% \usepackage{graphicx}
% \usepackage{lscape}
%\begin{landscape}
    \begin{table*}[]
        \centering
        \caption{quantitative comparisons of the accuracy/precision of current works}
        \label{tab:comparison}
        \resizebox{0.99\textwidth}{!}{%
            \begin{tabular}{@{}llllll@{}}
                \toprule
                Typical Work & Category                      & Method                                                                                                                          & Setup                                                                                       & Performance                                                                                                                                                                                                                                                                                                                                              & Note                                                                                                                                              \\ \midrule
                Kim et al.~\cite{Kim14}                      & \multirow{7}{*}{\begin{tabular}[c]{@{}l@{}}Sensing information \\based high-precision\\ robotic manipulation\end{tabular}}        & Force/Moment sensor                                                                         & 5-axis robot                                                                                    & \begin{tabular}[c]{@{}l@{}}Clearance: down to \SI{0.1}{\milli\meter} (H7/g6)\\ Duration: 6$\sim$\SI{10}{\second}\\ Initial error:\SI{8.145}{\milli\meter}/\ang{17.96}\end{tabular}                                                                     & Chamferless                                                                                                                                       \\
                Luo et al.~\cite{Luo2017}                    &                                                                                                                                 & Force/torque sensor                                                                         & 7-axis robot                                                                                    & \begin{tabular}[c]{@{}l@{}}Clearance: \SI{0.02}{\milli\meter}\\ Duration: \SI{40}{\second}(search phase) +\SI{6}{\second}(insertion\\ phase)\\ Initial orientation: \ang{7.5}\end{tabular}                                                             & \begin{tabular}[c]{@{}l@{}}Force/torque sensor is applied for\\ maintaining the contact force\end{tabular}                                        \\
                Zhang et al.~\cite{Zhang2017a}               &                                                                                                                                 & A two-phase scheme based on F/T sensor                                                      & 7-axis robot (Baxter)                                                                           & \begin{tabular}[c]{@{}l@{}}Clearance: \SI{0.5}{\milli\meter}\\ Duration: \SI{55}{\second}(single arm)/\SI{35}{\second}(dual arm)\\ Initial error:\SI{20}{\milli\meter}\end{tabular}                                                                    & -                                                                                                                                                 \\
                Takahashi et al.~\cite{Takahashi2016Passive} &                                                                                                                                 & \begin{tabular}[c]{@{}l@{}}Passive Alignment Principle (Force/torque\\ sensor)\end{tabular} & \begin{tabular}[c]{@{}l@{}}6-axis robot \\ (RV1A, Mitsubishi Electric Corporation)\end{tabular} & \begin{tabular}[c]{@{}l@{}}Clearance:  \SI{9}{\micro\meter} (50 H8/50 g7)\\ Duration: \SI{3500}{\milli\second}\\ Initial error: \SI{0.5}{\milli\meter}/\ang{1.4}\end{tabular}                                                                        & -                                                                                                                                                 \\
                Huang et al.~\cite{Huang13_1}                &                                                                                                                                 & Vision sensor                                                                               & 4-axis robot + 3DoF high-speed active peg                                                       & \begin{tabular}[c]{@{}l@{}}Clearance: \SI{4}{\milli\meter}\\ Duration: \SI{700}{\milli\second}\\ Initial error: \SI{2}{\milli\meter}\end{tabular}                                                                                                      & -                                                                                                                                                 \\
                Park et al.~\cite{Park2017}                  &                                                                                                                                 & Vision sensor                                                                               & 8-axis robot arm + 2DoF waist                                                                   & \begin{tabular}[c]{@{}l@{}}Clearance: \SI{0.01}{\milli\meter}\\ Duration: \SI{6.3}{\second}\\ Initial error: the maximum recognition error must be \\less than the peg radius (translation) /\\ be less than \ang{30} (orientation)\end{tabular}       & \begin{tabular}[c]{@{}l@{}}Chamferless\\ Wrist force sensor is not required, but\\ torque must be sensed for torque control\end{tabular}          \\
                Lin et al.~\cite{Lin2014}                    &                                                                                                                                 & \begin{tabular}[c]{@{}l@{}}Learning by demonstration (6DoF pose\\ information)\end{tabular} & 6-axis robot                                                                                    & \begin{tabular}[c]{@{}l@{}}Clearance: large\\ Duration: Not specified\\ Initial error: Not specified\end{tabular}                                                                                                                                      & \begin{tabular}[c]{@{}l@{}}Chamfer needed\\ Force/torque sensor is applied\end{tabular}                                                           \\
                \hline    
                Whitney et al.~\cite{Whitney1986b}           & \multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Compliant mechanism/device \\based high-precision\\ robotic manipulation\end{tabular}} & Remote Center of Compliance (RCC)                                                           & Not specified                                                                                   & Not specified                                                                                                                                                                                                                                          & \begin{tabular}[c]{@{}l@{}}Chamfer needed\\ Elastomer shear pad(ESP) needed for\\ simplification, but it fixed the compliance center\end{tabular} \\
                Baksys et al.~\cite{Baksys2010}              &                                                                                                                                 & RCC + Vibratory devices                                                                     & \begin{tabular}[c]{@{}l@{}}5-axis robot\\ (Mitsubishi RV-2AJ)\end{tabular}                      & \begin{tabular}[c]{@{}l@{}}Clearance: \SI{0.22}{\milli\meter} (peg diameter d = \SI{17.88}{\milli\meter}, hole diameter D = \SI{18.10}{\milli\meter})\\ Duration: alignment: \SIrange{30}{60}{\milli\second} (related to\\ axial misalignment, pressing force and excitation frequency); insertion:\\ \SIrange{200}{300}{\milli\second} (related to insertion speed, excitation frequency and excitation\\ amplitude)\\ Initial error: \SI{3}{\milli\meter}\end{tabular} & Passive compliance                                                                                                                                \\
                Balletti et al.~\cite{Balletti2012}          &                                                                                                                                 & Variable Impedance Actuator (VIA)                                                           & 4-axis robot * 2 (CubeBot)                                                                      & \begin{tabular}[c]{@{}l@{}}Clearance: \SI{0.5}{\milli\meter}\\ Duration: \SI{25}{\second}\\ Initial error: $\sim$\SI{20}{\milli\meter}\end{tabular}                                                                                                    & \begin{tabular}[c]{@{}l@{}}Simple control\\ Simple sensor (position sensor, no force\\ sensor)\end{tabular}                                       \\
                \hline
                Li et al.~\cite{Li2017}                      & \begin{tabular}[c]{@{}l@{}}Environmental constraints \\based high-precision\\ robotic manipulation\end{tabular}                   & Attractive Region in Environment                                                            & \begin{tabular}[c]{@{}l@{}}6-axis robot\\ (Fanuc M-6iB)\end{tabular}                            & \begin{tabular}[c]{@{}l@{}}Clearance: \SI{0.05}{\milli\meter}\\ Duration: $\sim$\SI{13}{\second}\\ Initial error: \SI{0.5}{\milli\meter}/\ang{1.5}\end{tabular}                                                                                        & -                                                                                                                                                 \\ \bottomrule
            \end{tabular}%
        }
    \end{table*}
%\end{landscape}

Currently, the primary research of robot high-precision operation is still converged on sensing information based methods. 
Among the works, force/torque information plays a vital role in the realization of compliance control, while the visual and range information based methods play a significant role in recognition, measurement, learning and so on. 
The precision of sensing information based methods mainly depends on that of the sensors. 
The main problems include: 
(a) obtaining some state information by sensors is difficult\DIFdelbegin \DIFdel{. 
}\DIFdelend \DIFaddbegin \DIFadd{, 
}\DIFaddend (b) high-precision information is vulnerable to noise interference\DIFdelbegin \DIFdel{. 
}\DIFdelend \DIFaddbegin \DIFadd{, and  
}\DIFaddend (c) collecting and processing high-precision sensing data is very time-consuming.

For compliant mechanism/device-based methods, 
\DIFaddbegin \DIFadd{the }\DIFaddend remote compliance center device is a classical method to solve the problem of robot high-precision peg-in-hole assembly. 
Variable stiffness actuator implements a new possibility to achieve compliant motion by changing the driving part.
By increasing the complexity of \DIFaddbegin \DIFadd{the }\DIFaddend mechanism design, the complexity of the control algorithm is reduced, and the requirement of the precision of the robot is decreased. 
The main problem is that the flexibility of the system is limited and the \DIFdelbegin \DIFdel{generalization }\DIFdelend \DIFaddbegin \DIFadd{general }\DIFaddend ability to manipulate different objects is limited.

For Environmental constraint-based methods, \DIFdelbegin \DIFdel{attractive region in environment}\DIFdelend \DIFaddbegin \DIFadd{ARIE}\DIFaddend , caging, extrinsic dexterity and many other theoretical approaches are proposed.
These works make use of the constraint relation in the manipulation process, realizing a variety of high-precision operations such as assembly, grasping, localization, flipping and so on. 
The main difficulty of this kind of method is how to find and construct the available constraint relation and realize the change from the initial state to the target state.

There is also some preliminary discovery in sensing-constraint integration methods and human-inspired methods.
Future efforts would possibly be \DIFdelbegin \DIFdel{paid on improving }\DIFdelend \DIFaddbegin \DIFadd{funded to improve }\DIFaddend the performance of learning based manipulation methods (which would enhance the intelligence of the robotic system), sensing-constraint integration methods (which reduce the dependency of high-precision sensing information for the robotic system) and the human-inspired methods (which increase compliance of the robotic system).

\appendices

\section*{Acknowledgment}

The authors would like to thank Xu Yang for his constructive suggestions on improving the structure of this manuscript. The authors would also like to thank Xiaoqing Li for her help in collecting some of the relevant papers in robotic assembly. The authors would also like to thank Shanli Zhong and Jiahao Chen for their help on simulation.

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,./bib/ref}


\begin{IEEEbiography}
    [{\includegraphics[width=1.00\textwidth]{photo_qiaohong.jpg}}]{Hong Qiao} (SM'06) received the B.Eng. and M.Eng. degrees both from Xi'an Jiaotong University, Xi’an, China, in 1986 and 1989, respectively, the M.Phil. degree from the University of Strathclyde, Strathclyde, U.K. in 1997, and the Ph.D. degree from De Montfort University, Leicester, U.K., in 1995.

    She held teaching and research positions with universities in the U.K. and Hong Kong, from 1990 to 2004. She is currently a `100-Talents Project' Professor with the State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences (CASIA), Beijing, China. Her current research interests include robotic manipulation, robotic vision, bio-inspired intelligent robot, brain-like intelligence, etc.

    She is the first to propose the concept of the attractive region in environment (ARIE) in strategy investigation which is later successfully applied for robot assembly, robot grasping, and part recognition, which is reported in \textit{Advanced Manufacturing Alert} (New York, NY, USA: Wiley, 1999). She is a Member of the Administrative Committee of the IEEE Robotics and Automation Society (2014-2016, 2017-2019), the IEEE Medal for Environmental and Safety Technologies Committee (2014-2018), and the RAS Long Range Planning Committee (2016-2017). She is on the Editorial Boards of 5 IEEE Transactions and the Editor-in-Chief of Assembly Automation.
\end{IEEEbiography}
\vfill
\begin{IEEEbiography}[{\includegraphics[width=1.00\textwidth]{photo_lirui}}]{Rui Li}
    received the B.Eng degree in automation engineering from the University of Electronic Science and Technology of China \DIFaddbegin \DIFadd{(UESTC)}\DIFaddend , Chengdu, China, in \DIFdelbegin \DIFdel{2013.
    }%DIFDELCMD < 

%DIFDELCMD <     %%%
\DIFdel{He is currently a }\DIFdelend \DIFaddbegin \DIFadd{2013 and the }\DIFaddend Ph.D\DIFdelbegin \DIFdel{candidate and research assistant with }\DIFdelend \DIFaddbegin \DIFadd{. degree from }\DIFaddend the Institute of Automation, Chinese Academy of Science \DIFdelbegin \DIFdel{. His current }\DIFdelend \DIFaddbegin \DIFadd{(CASIA), Beijing, China in 2018, respectively.
    }

    \DIFadd{From 2014 to 2018, he served as the Editorial Assistant of Assembly Automation. He is currently a postdoc researcher with Informatics 6, Technical University of Munich. His }\DIFaddend research interests include \DIFdelbegin \DIFdel{robotic compliance, }\DIFdelend intelligent robot system \DIFdelbegin \DIFdel{, }\DIFdelend and high-precision \DIFdelbegin \DIFdel{robotic manipulation }\DIFdelend \DIFaddbegin \DIFadd{assembly}\DIFaddend .
\end{IEEEbiography}
\vfill

\end{document}
